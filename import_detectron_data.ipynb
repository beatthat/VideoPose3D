{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from utils.dataset import extract_data, get_poses, poses_2_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvertHumanEva.m\t\t\tdata_3d_h36m.npz.sav\r\n",
      "__init.py__\t\t\t\tdata_utils.py\r\n",
      "convert_cdf_to_mat.m\t\t\tdetectron\r\n",
      "data_2d_h36m_cpn_ft_h36m_dbb.npz\th36m.zip\r\n",
      "data_2d_h36m_detectron_custom_h36m.npz\tprepare_data_2d_h36m_generic.py\r\n",
      "data_2d_h36m_detectron_ft_h36m.npz\tprepare_data_2d_h36m_sh.py\r\n",
      "data_2d_h36m_gt.npz\t\t\tprepare_data_h36m.py\r\n",
      "data_2d_h36m_sh_pt_mpii.npz\t\tprepare_data_humaneva.py\r\n",
      "data_3d_h36m.npz\t\t\tvideos\r\n"
     ]
    }
   ],
   "source": [
    "PATH='/docker_host'\n",
    "DATA_PATH = os.path.join(PATH, 'data')\n",
    "!ls {DATA_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_detectron_poses(path):\n",
    "    # Latin1 encoding because Detectron runs on Python 2.7\n",
    "    data = np.load(path, encoding='latin1')\n",
    "    kp = data['keypoints']\n",
    "    bb = data['boxes']\n",
    "    results = []\n",
    "    for i in range(len(bb)):\n",
    "        if len(bb[i][1]) == 0:\n",
    "            assert i > 0\n",
    "            # Use last pose in case of detection failure\n",
    "            results.append(results[-1])\n",
    "            continue\n",
    "        best_match = np.argmax(bb[i][1][:, 4])\n",
    "        keypoints = kp[i][1][best_match].T.copy()\n",
    "        results.append(keypoints)\n",
    "    results = np.array(results)\n",
    "    # return results[:, :, 4:6] # Soft-argmax\n",
    "    return results[:, :, [0, 1, 3]] # Argmax + score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keypoints_2d_to_datasets(poses, subject='S1', action='Default'):\n",
    "    \"\"\"\n",
    "    given a sequence of 2d keypoints for a single subject and action, \n",
    "    create the datasets necessary to predict 3d keypoints with Video2Pose run.py.\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset_2d = dict({\n",
    "        'positions_2d': dict({\n",
    "            subject: dict({\n",
    "                action: [poses] # array of cameras but we have only one camera\n",
    "            })\n",
    "        }),\n",
    "        'metadata': dict({\n",
    "            'layout_name': 'h36m', \n",
    "            'num_joints': 17, \n",
    "            'keypoints_symmetry': [[4, 5, 6, 11, 12, 13], [1, 2, 3, 14, 15, 16]]\n",
    "        })\n",
    "    })\n",
    "    \n",
    "    # to use run.py to generate 3d predictions, \n",
    "    # it requires a 3d dataset that matches \n",
    "    # all the subjects and actions in the 2d dataset\n",
    "    dataset_3d_fake = dict({\n",
    "        'positions_3d': dict({\n",
    "            subject: dict({\n",
    "                action: np.ones((poses.shape[0], 32, 3), dtype=np.float32)\n",
    "            })\n",
    "        })\n",
    "    })\n",
    "    \n",
    "    return dataset_2d, dataset_3d_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_2d_from_detectron(detectron_data, output_file_2d, output_file_3d):\n",
    "    keypoints_2d = import_detectron_poses(detectron_data)\n",
    "    dataset_2d, dataset_3d = keypoints_2d_to_datasets(keypoints_2d)\n",
    "    np.savez(output_file_2d, **dataset_2d)\n",
    "    np.savez(output_file_3d, **dataset_3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/docker_host/data/detectron/keypoints.npz\r\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 11 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7d1b7a4c561b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh36m_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHuman36mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHuman36mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file_3d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/videopose3d/common/h36m_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, remove_static_joints)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;31m# Rewire shoulders to the correct parents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skeleton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skeleton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 11 is out of bounds for axis 0 with size 5"
     ]
    }
   ],
   "source": [
    "detectron_file = os.path.join(DATA_PATH, 'detectron', 'keypoints.npz')\n",
    "output_file_2d = os.path.join(DATA_PATH, 'data_2d_h36m_detectron_custom_h36m.npz')\n",
    "output_file_3d = os.path.join(DATA_PATH, 'data_3d_h36m.npz')\n",
    "!ls {detectron_file}\n",
    "\n",
    "# from data.data_utils import import_detectron_poses\n",
    "\n",
    "prepare_data_2d_from_detectron(detectron_file, output_file_2d, output_file_3d)\n",
    "\n",
    "from common.h36m_dataset import Human36mDataset\n",
    "\n",
    "dataset = Human36mDataset(output_file_3d)\n",
    "print(type(dataset))\n",
    "\n",
    "# print(f'kps.shape={kps.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata={'layout_name': 'h36m', 'num_joints': 17, 'keypoints_symmetry': [[4, 5, 6, 11, 12, 13], [1, 2, 3, 14, 15, 16]]}\n",
      "(3477, 17, 2)\n"
     ]
    }
   ],
   "source": [
    "# data_file = os.path.join(DATA_PATH, 'data_2d_h36m_detectron_ft_h36m.npz')\n",
    "# positions_2d, metadata = extract_data(data_file)\n",
    "# print(f'metadata={metadata}')\n",
    "# poses = get_poses(positions_2d, action='Walking 1')\n",
    "# # print(f'poses={type(poses)}')\n",
    "# print(poses.shape) # [3000, 17, 2] 3000 frames, 17 keypoints/frame, 2 dims/keypoint (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1, 2], [3, 4]]]\n"
     ]
    }
   ],
   "source": [
    "# test_poses = [\n",
    "#     [[1,2], [3,4]]\n",
    "# ]\n",
    "\n",
    "# test_path = os.path.join(DATA_PATH, 'test1.npz')\n",
    "# test_arch = poses_2_archive(test_poses)\n",
    "# # \n",
    "# np.savez(test_path, **test_arch)\n",
    "\n",
    "# positions_2d, metadata = extract_data(test_path)\n",
    "# poses_round_trip = get_poses(positions_2d)\n",
    "# # print(f'poses={type(poses)}')\n",
    "# print(poses_round_trip) # [3000, 17, 2] 3000 frames, 17 keypoints/frame, 2 dims/keypoint (x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
